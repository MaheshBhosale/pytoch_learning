{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1b0+4cf3225'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import inspect\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22c6954b2b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 8\n",
    "num_classes = 1\n",
    "num_epochs=500\n",
    "batch_size=100\n",
    "learning_rate=0.1\n",
    "torch.manual_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegresion(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegresion, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, 6)\n",
    "        self.l2 = nn.Linear(6, 4)\n",
    "        self.l3 = nn.Linear(4, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        out3 = self.sigmoid(self.l3(out2))\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Titanic_Train_Dataloader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = pd.read_csv('../Data/new_data.csv', delimiter=',', dtype = np.float32, header = 0)\n",
    "        self.y_data = pd.read_csv('../Data/new_targets.csv', delimiter=',', dtype = np.float32, header = 0)\n",
    "        self.x_data = torch.from_numpy(self.x_data.as_matrix())\n",
    "        self.y_data = torch.from_numpy(self.y_data.as_matrix())\n",
    "        self.len = self.x_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Titanic_Test_Dataloader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = pd.read_csv('../Data/new_test_data.csv', delimiter=',', dtype = np.float32, header = 0)\n",
    "        self.y_data = pd.read_csv('../Data/gender_submission.csv', delimiter=',', dtype = np.float32, header = 0)\n",
    "        self.x_data = torch.from_numpy(self.x_data.as_matrix())\n",
    "        self.y_data = torch.from_numpy(self.y_data.as_matrix())\n",
    "        self.len = self.x_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegresion(input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_data = Titanic_Train_Dataloader()\n",
    "train_loader = DataLoader(dataset = titanic_train_data, batch_size=32, shuffle = True)\n",
    "titanic_test_data = Titanic_Test_Dataloader()\n",
    "test_loader = DataLoader(dataset = titanic_test_data, batch_size=32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 416\n"
     ]
    }
   ],
   "source": [
    "crieterion = nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "total_train_loss = 0\n",
    "total_test_loss = 0\n",
    "num_train_examples = 891\n",
    "num_test_examples = test_loader.__len__()*32\n",
    "training_losses = []\n",
    "testing_losses = []\n",
    "iterations = []\n",
    "print(num_train_examples, num_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        for _index, train_data in enumerate(train_loader):\n",
    "            x_train, y_train = train_data\n",
    "            x_train = Variable(x_train)\n",
    "            y_train = Variable(y_train)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_train)\n",
    "            train_loss = crieterion(outputs, y_train)\n",
    "            total_train_loss += train_loss.data[0]\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            for index, test_data in enumerate(test_loader):\n",
    "                x_test, y_test = test_data\n",
    "                x_test = Variable(x_test)\n",
    "                y_test = Variable(y_test)\n",
    "                y_pred = model(x_test)\n",
    "                test_loss = crieterion(y_pred, y_test)\n",
    "                total_test_loss += test_loss.data[0]    \n",
    "        total_train_loss /= num_train_examples\n",
    "        total_test_loss /= num_test_examples\n",
    "        training_losses.append(total_train_loss)\n",
    "        testing_losses.append(total_test_loss)\n",
    "        iterations.append(epoch)\n",
    "#         print(f'Train_loss[{epoch}/{num_epochs}] {total_train_loss} Test_loss [{epoch}/{num_epochs}] {total_test_loss}')\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.585591203891314,\n",
       " 0.5759861029397982,\n",
       " 0.5742927378473374,\n",
       " 0.5749170303058165,\n",
       " 0.5739909742887204,\n",
       " 0.5735288376991565,\n",
       " 0.5741194493782061,\n",
       " 0.5730630729634029,\n",
       " 0.5728157973633363,\n",
       " 0.5730570805473969,\n",
       " 0.572368249297142,\n",
       " 0.5715124051158245,\n",
       " 0.570938804688362,\n",
       " 0.5711059498672302,\n",
       " 0.5695278815065439,\n",
       " 0.56884601038809,\n",
       " 0.5692376077461702,\n",
       " 0.5668160584397041,\n",
       " 0.5658381091287503,\n",
       " 0.5645631258017741,\n",
       " 0.5628353027770152,\n",
       " 0.5610090327950624,\n",
       " 0.5584995586138505,\n",
       " 0.5562380964939411,\n",
       " 0.5529348956277738,\n",
       " 0.5499644646277795,\n",
       " 0.5459463959559798,\n",
       " 0.5419302076960986,\n",
       " 0.5374626137602788,\n",
       " 0.5318730340984005,\n",
       " 0.5266853699890467,\n",
       " 0.5206349415418047,\n",
       " 0.5143349988815876,\n",
       " 0.507410252180237,\n",
       " 0.5005438847180742,\n",
       " 0.4938967960815017,\n",
       " 0.4864995004609227,\n",
       " 0.479087270079897,\n",
       " 0.47160225898887104,\n",
       " 0.4641127997579483,\n",
       " 0.4563798023960911,\n",
       " 0.44868565837924296,\n",
       " 0.4420859014185575,\n",
       " 0.4345098607098827,\n",
       " 0.4268314219438113,\n",
       " 0.4193167226532331,\n",
       " 0.4116536148895438,\n",
       " 0.40447596080887777,\n",
       " 0.3974744009140592,\n",
       " 0.3917641080199526,\n",
       " 0.38437084237543434,\n",
       " 0.37754171506430095,\n",
       " 0.3717085272073746,\n",
       " 0.36628855399500865,\n",
       " 0.36155489552766085,\n",
       " 0.3569109676262507,\n",
       " 0.35240615546130216,\n",
       " 0.3479912599835258,\n",
       " 0.34543514545433796,\n",
       " 0.34217917650508195,\n",
       " 0.3389237758058768,\n",
       " 0.33662928121451,\n",
       " 0.3346901105430264,\n",
       " 0.3325676561261599,\n",
       " 0.3308977691026834,\n",
       " 0.32999067345204264,\n",
       " 0.32676740373986274,\n",
       " 0.325813948821563,\n",
       " 0.3256633450062229,\n",
       " 0.32465609134389806,\n",
       " 0.32153633039874524,\n",
       " 0.3197835794148537,\n",
       " 0.31682828054405177,\n",
       " 0.31580723327799487,\n",
       " 0.3135907670411353,\n",
       " 0.31348731465494406,\n",
       " 0.31055447989358353,\n",
       " 0.30838292847888976,\n",
       " 0.30643645813688636,\n",
       " 0.30657905952718395,\n",
       " 0.3051732947978263,\n",
       " 0.30683463593371785,\n",
       " 0.30133625223802835,\n",
       " 0.3018770030198189,\n",
       " 0.2985308967315807,\n",
       " 0.2988676460674749,\n",
       " 0.29839005289026177,\n",
       " 0.2970543414569245,\n",
       " 0.2948216953887962,\n",
       " 0.2946979582238083,\n",
       " 0.29373557310408127,\n",
       " 0.29129643405142885,\n",
       " 0.29059969189648444,\n",
       " 0.2896299261528139,\n",
       " 0.28834247728809714,\n",
       " 0.2875981772175202,\n",
       " 0.28856519842520356,\n",
       " 0.28631880392248815,\n",
       " 0.2850366576503103,\n",
       " 0.2839546756317409,\n",
       " 0.2841693251035534,\n",
       " 0.2812369925041611,\n",
       " 0.2796591370939635,\n",
       " 0.27844848988864285,\n",
       " 0.2787230899557471,\n",
       " 0.27802819665521383,\n",
       " 0.2762839410167474,\n",
       " 0.27672749940449226,\n",
       " 0.27790777320758653,\n",
       " 0.27338850379993135,\n",
       " 0.2714388128728248,\n",
       " 0.27330025647265405,\n",
       " 0.27225542329968166,\n",
       " 0.2705692575814632,\n",
       " 0.2668087727820071,\n",
       " 0.2717149129782159,\n",
       " 0.26537917382442033,\n",
       " 0.2679191717806344,\n",
       " 0.264796368455371,\n",
       " 0.26580061054287046,\n",
       " 0.2658183745538386,\n",
       " 0.2658246296744507,\n",
       " 0.26424943222306096,\n",
       " 0.2608699699720511,\n",
       " 0.2650735438443147,\n",
       " 0.2624736140983609,\n",
       " 0.25919496121171576,\n",
       " 0.26166952297521323,\n",
       " 0.2575489005002265,\n",
       " 0.25984305351112896,\n",
       " 0.2590856956891142,\n",
       " 0.26044651575816363,\n",
       " 0.25644035028437007,\n",
       " 0.25587362638459754,\n",
       " 0.26022689091041684,\n",
       " 0.26064127493793,\n",
       " 0.2579888903822463,\n",
       " 0.25593934745456165,\n",
       " 0.2571413677114134,\n",
       " 0.2553439710934002,\n",
       " 0.25342124274287087,\n",
       " 0.2545092344785539,\n",
       " 0.2533522041227955,\n",
       " 0.25226189450432474,\n",
       " 0.25371372427504796,\n",
       " 0.25512051288611615,\n",
       " 0.2538108744013768,\n",
       " 0.2541409327218739,\n",
       " 0.25330922107857007,\n",
       " 0.25028651118135226,\n",
       " 0.24977843255664295,\n",
       " 0.2520817110601526,\n",
       " 0.2523577625218492,\n",
       " 0.25499525680564916,\n",
       " 0.25487795346774733,\n",
       " 0.2534350769307751,\n",
       " 0.2535202780093711,\n",
       " 0.2507722263152783,\n",
       " 0.2506022469785351,\n",
       " 0.25212886191617984,\n",
       " 0.2510536452755332,\n",
       " 0.25179047667636323,\n",
       " 0.2504366605112759,\n",
       " 0.2509178864912918,\n",
       " 0.25072987803902763,\n",
       " 0.2495452159514221,\n",
       " 0.24592373681326324,\n",
       " 0.25064174411818385,\n",
       " 0.2530357147781895,\n",
       " 0.24776178623478,\n",
       " 0.2501098315159862,\n",
       " 0.2500269952086875,\n",
       " 0.24722726449656945,\n",
       " 0.24938601201686722,\n",
       " 0.2515067155114733,\n",
       " 0.24926692369179085,\n",
       " 0.2477960057484989,\n",
       " 0.24952320729453975,\n",
       " 0.2463551010363377,\n",
       " 0.247785773450652,\n",
       " 0.24835855098297963,\n",
       " 0.24771816147348055,\n",
       " 0.2486795182339847,\n",
       " 0.2471330355709562,\n",
       " 0.25065138276952964,\n",
       " 0.24836181319103792,\n",
       " 0.2496011319498603,\n",
       " 0.24601643439382315,\n",
       " 0.24671856629160735,\n",
       " 0.24832653927688414,\n",
       " 0.24798360742771855,\n",
       " 0.2494850866854764,\n",
       " 0.24744565287031806,\n",
       " 0.2447694201165667,\n",
       " 0.24654165830893013,\n",
       " 0.24837036036814636,\n",
       " 0.24504127242387488,\n",
       " 0.24706856519556963,\n",
       " 0.2465358843955283,\n",
       " 0.24595980034567988,\n",
       " 0.24733568559615657,\n",
       " 0.24571479620555273,\n",
       " 0.24698545640477768,\n",
       " 0.24982620310038328,\n",
       " 0.246067301191103,\n",
       " 0.24606807673206696,\n",
       " 0.24450854469950384,\n",
       " 0.2456612646078261,\n",
       " 0.2501637227833271,\n",
       " 0.24853929282667545,\n",
       " 0.24651916643891197,\n",
       " 0.2485834647041674,\n",
       " 0.2439391967267371,\n",
       " 0.24830306618689343,\n",
       " 0.24257728926694164,\n",
       " 0.24703905315926442,\n",
       " 0.248097181535111,\n",
       " 0.24716801364691213,\n",
       " 0.24693119615459672,\n",
       " 0.24684918725576538,\n",
       " 0.24380330411860576,\n",
       " 0.24893111101566598,\n",
       " 0.2464775383615723,\n",
       " 0.2468315276603859,\n",
       " 0.2438278217943242,\n",
       " 0.24448587254692727,\n",
       " 0.24509611550288704,\n",
       " 0.24695774311056504,\n",
       " 0.24637813328836972,\n",
       " 0.24651948025879952,\n",
       " 0.2466840704616446,\n",
       " 0.24554642082120365,\n",
       " 0.24877683786102212,\n",
       " 0.2476233429669474,\n",
       " 0.24439989983175808,\n",
       " 0.24443153302686718,\n",
       " 0.24651333532081202,\n",
       " 0.24561345827980682,\n",
       " 0.24545985175511584,\n",
       " 0.24709089927805158,\n",
       " 0.24492050503165677,\n",
       " 0.24514460696194035,\n",
       " 0.2428300864278124,\n",
       " 0.24671132038705623,\n",
       " 0.24743261876014563,\n",
       " 0.24566951673477888,\n",
       " 0.2492063739695228,\n",
       " 0.24738145608884785,\n",
       " 0.24471046696775234,\n",
       " 0.24464452212962967,\n",
       " 0.2456611247661595,\n",
       " 0.24862200641431487,\n",
       " 0.24469339672046211,\n",
       " 0.24912833975842938,\n",
       " 0.24845574491728956,\n",
       " 0.2441597951647754,\n",
       " 0.2477368273629019,\n",
       " 0.24430177482561424,\n",
       " 0.2457697378972975,\n",
       " 0.24710006908012125,\n",
       " 0.24493216508283064,\n",
       " 0.24650328889345893,\n",
       " 0.24708271399140358,\n",
       " 0.24764855890176618,\n",
       " 0.24584029371348712,\n",
       " 0.24586807556736928,\n",
       " 0.24979446853439397,\n",
       " 0.24658790742978454,\n",
       " 0.2448231789570015,\n",
       " 0.24487701001075599,\n",
       " 0.24412016212367094,\n",
       " 0.24789482956895462,\n",
       " 0.2457737884699152,\n",
       " 0.24557772583256549,\n",
       " 0.2450599934762487,\n",
       " 0.24799749000857657,\n",
       " 0.2494643052610067,\n",
       " 0.2453671325571262,\n",
       " 0.24232348810451534,\n",
       " 0.246207124983462,\n",
       " 0.2461840259627654,\n",
       " 0.24897212574545008,\n",
       " 0.2425321998217931,\n",
       " 0.2466564578219102,\n",
       " 0.2473489936763564,\n",
       " 0.2472749983605284,\n",
       " 0.24797669253670251,\n",
       " 0.24569597102415103,\n",
       " 0.2481784880734407,\n",
       " 0.2517552217110418,\n",
       " 0.2456347297411412,\n",
       " 0.24732612589230904,\n",
       " 0.2480614800722553,\n",
       " 0.24634239908594352,\n",
       " 0.24634668531899268,\n",
       " 0.24956188995677692,\n",
       " 0.24718828674835655,\n",
       " 0.2465318517329601,\n",
       " 0.24874016438395932,\n",
       " 0.24860572397637254,\n",
       " 0.24990492374994433,\n",
       " 0.24535247253683898,\n",
       " 0.24816817267296407,\n",
       " 0.24388895764087254,\n",
       " 0.24717884353147104,\n",
       " 0.24852667057600158,\n",
       " 0.24703275963950616,\n",
       " 0.24893588236031625,\n",
       " 0.24883852992206812,\n",
       " 0.24609054023256668,\n",
       " 0.2512458567865766,\n",
       " 0.2467014967607191,\n",
       " 0.24510074134629506,\n",
       " 0.24867181583809164,\n",
       " 0.2486240748101129,\n",
       " 0.24996246093024427,\n",
       " 0.2469750281709891,\n",
       " 0.24740496438999587,\n",
       " 0.24851359849652419,\n",
       " 0.25033701225542104,\n",
       " 0.2467637236158435,\n",
       " 0.24640176366441524,\n",
       " 0.24688809526224548,\n",
       " 0.24906590391093722,\n",
       " 0.24895301482711846,\n",
       " 0.2518515638792171,\n",
       " 0.24699185086557499,\n",
       " 0.25132375980655736,\n",
       " 0.24701189984065983,\n",
       " 0.248455392017674,\n",
       " 0.24606631979202995,\n",
       " 0.24656718005784428,\n",
       " 0.24711822965540564,\n",
       " 0.24968839189610803,\n",
       " 0.2506605746726004,\n",
       " 0.2485441014600488,\n",
       " 0.24594793701544404,\n",
       " 0.2481279528986376,\n",
       " 0.24921305022703913,\n",
       " 0.24521113552439672,\n",
       " 0.24795712072115678,\n",
       " 0.24959610456314224,\n",
       " 0.24761363505744016,\n",
       " 0.247744505902609,\n",
       " 0.24773509979534608,\n",
       " 0.2538045785533121,\n",
       " 0.26037118279446775,\n",
       " 0.252132786043848,\n",
       " 0.2531286323478875,\n",
       " 0.2477398284782584,\n",
       " 0.25224408876294124,\n",
       " 0.24701112594742042,\n",
       " 0.2474300218746066,\n",
       " 0.24877921538427472,\n",
       " 0.24750514851453212,\n",
       " 0.24813393267014852,\n",
       " 0.2475452361485133,\n",
       " 0.24869295245466325,\n",
       " 0.24894746722510228,\n",
       " 0.24920453124034864,\n",
       " 0.25207527092872906,\n",
       " 0.24713312042877078,\n",
       " 0.2457702004780563,\n",
       " 0.24908734435358873,\n",
       " 0.2464971009713526,\n",
       " 0.2527211995150607,\n",
       " 0.2522650874004914,\n",
       " 0.24693816839359128,\n",
       " 0.24716090145879066,\n",
       " 0.24743762336528072,\n",
       " 0.248534740987592,\n",
       " 0.25111097742158633,\n",
       " 0.2514965903873627,\n",
       " 0.2530597966665832,\n",
       " 0.25272551787873876,\n",
       " 0.24783688285746253,\n",
       " 0.24679275208081192,\n",
       " 0.24998174614917773,\n",
       " 0.252277601402826,\n",
       " 0.25121940697471684,\n",
       " 0.2505872702727524,\n",
       " 0.25157765134309346,\n",
       " 0.2471897705959586,\n",
       " 0.2543171799311844,\n",
       " 0.25112877144979745,\n",
       " 0.25345603795722127,\n",
       " 0.2514132927171886,\n",
       " 0.2536937672501573,\n",
       " 0.24903095674772674,\n",
       " 0.2527782004326582,\n",
       " 0.24773011875983614,\n",
       " 0.2495831949994541,\n",
       " 0.25489401595237166,\n",
       " 0.2511952667353818,\n",
       " 0.24773882805871275,\n",
       " 0.24986517909341133,\n",
       " 0.2485283064441039,\n",
       " 0.2512214412697806,\n",
       " 0.24848298187582538,\n",
       " 0.25262988032773137,\n",
       " 0.2511867562022347,\n",
       " 0.24941598204895854,\n",
       " 0.25233122591788953,\n",
       " 0.25311892493986166,\n",
       " 0.2482366540397589,\n",
       " 0.25144419837026644,\n",
       " 0.2479478153400123,\n",
       " 0.24931517214729235,\n",
       " 0.25068524952691335,\n",
       " 0.24958043004601047,\n",
       " 0.25233392148780137,\n",
       " 0.2516166970420342,\n",
       " 0.25162516910439503,\n",
       " 0.2534326574621865,\n",
       " 0.2501843014302162,\n",
       " 0.2514049028977752,\n",
       " 0.2513935539441613,\n",
       " 0.25298789913694447,\n",
       " 0.2532934302893969,\n",
       " 0.2531450685256949,\n",
       " 0.250184040910636,\n",
       " 0.25040078797162724,\n",
       " 0.25379945366428447,\n",
       " 0.25385847365340364,\n",
       " 0.2533037598746327,\n",
       " 0.2510536861104461,\n",
       " 0.25390506299355853,\n",
       " 0.25207263729176843,\n",
       " 0.2504354168374378,\n",
       " 0.2516981792421295,\n",
       " 0.2534815192294235,\n",
       " 0.2514904835619606,\n",
       " 0.25100000833089536,\n",
       " 0.2536946506812595,\n",
       " 0.2536443766707984,\n",
       " 0.25247473205224824,\n",
       " 0.25471409560682684,\n",
       " 0.2504249456553505,\n",
       " 0.25116169850270337,\n",
       " 0.2539166755831012,\n",
       " 0.2535995674462846,\n",
       " 0.25792881011819613,\n",
       " 0.2534880401351704,\n",
       " 0.25348248117818284,\n",
       " 0.2525041614157649,\n",
       " 0.25342838620193875,\n",
       " 0.24930474045686424,\n",
       " 0.25553201661946684,\n",
       " 0.25218170139795315,\n",
       " 0.2531996099994733,\n",
       " 0.25029858807101846,\n",
       " 0.25523955983897817,\n",
       " 0.2526022638194263,\n",
       " 0.24980132213722056,\n",
       " 0.25205162400379777,\n",
       " 0.2543200633775156,\n",
       " 0.25416887748556644,\n",
       " 0.25453067794800377,\n",
       " 0.2523631600018304,\n",
       " 0.2565828391279166,\n",
       " 0.2596223128135674,\n",
       " 0.25536324488572204,\n",
       " 0.2573208143003285,\n",
       " 0.2514534821160711,\n",
       " 0.24963845341251448,\n",
       " 0.2542648166776277,\n",
       " 0.25249552819877863,\n",
       " 0.2549916439546415,\n",
       " 0.25019836565479636,\n",
       " 0.25846713670314503,\n",
       " 0.2544371033660494,\n",
       " 0.2547792243735435,\n",
       " 0.2528082074490018,\n",
       " 0.2525281416108975,\n",
       " 0.25424544266066873,\n",
       " 0.2545564521748859,\n",
       " 0.2534770930830676,\n",
       " 0.2561596605855112,\n",
       " 0.2566272928379476,\n",
       " 0.25592308992949814,\n",
       " 0.2538827872620179,\n",
       " 0.2547196410954572,\n",
       " 0.25492517825645894,\n",
       " 0.2520926913533073,\n",
       " 0.25862168896800053,\n",
       " 0.2551165966746899,\n",
       " 0.255589218917661,\n",
       " 0.24995987908914685,\n",
       " 0.2561148599578211,\n",
       " 0.25790152064739513,\n",
       " 0.2564427902420553,\n",
       " 0.25835660096401203,\n",
       " 0.2542528606807956,\n",
       " 0.25419447331044537,\n",
       " 0.2529358171428052,\n",
       " 0.2549145767966715,\n",
       " 0.25513218715786934,\n",
       " 0.25581048131705475,\n",
       " 0.2552859964422308,\n",
       " 0.2553390568623749]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(iterations)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, 200])\n",
    "axes.set_ylim([0.01, 0.5])\n",
    "plt.plot(iterations, training_losses)\n",
    "plt.plot(iterations, testing_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 88.9423076923077%\n"
     ]
    }
   ],
   "source": [
    "index\n",
    "correct = 0\n",
    "for index, data in enumerate(test_loader):\n",
    "    x_data, y_data = data\n",
    "    x_data = Variable(x_data)\n",
    "    y_data = Variable(y_data)\n",
    "    y_pred = model(x_data)\n",
    "    y_data.squeeze_()\n",
    "    y_pred.squeeze_()\n",
    "#     print(y_pred[0],y_data[0])\n",
    "    for i in range(32):\n",
    "        if y_pred[i].data.numpy() < 0.5 and y_data[i].data.numpy() == 0:\n",
    "                correct = correct + 1\n",
    "        if y_pred[i].data.numpy() >= 0.5 and y_data[i].data.numpy() == 1:\n",
    "                correct = correct + 1\n",
    "index = index + 1\n",
    "total = 32 * index\n",
    "accuracy = correct/total\n",
    "print(f'Accuracy is {accuracy*100}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
